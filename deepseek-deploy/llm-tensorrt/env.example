# TensorRT-LLM集群配置环境变量示例
# 复制此文件到.env并根据需要修改,‼️是需要修改的地方

# ‼️Docker 镜像配置
DOCKER_IMAGE="baseten/tensorrt_llm-release:0.19.0rc0"

# SSH端口配置
SSH_PORT=2233

# 目录配置
# 免密登录秘钥路径
SSHKEY_DIR="./sshkey"

# ‼️共享存储中模型文件的根路径
MODEL_REPO_DIR="/mnt/share/deepseek-ai"

# ‼️节点配置
# 设置为true表示当前节点是主节点，将安装mpich
# 设置为false表示当前节点是从节点，不安装mpich
IS_MASTER=false
MASTER_ADDR=10.83.0.101
MASTER_PORT=29500

# IB网络
GLOO_SOCKET_IFNAME=bond0
NCCL_SOCKET_IFNAME=bond0
NCCL_IB_HCA=mlx5_0,mlx5_1,mlx5_4,mlx5_5

# TensorRT-LLM服务相关配置
# 量化参数-TensorRT-LLM默认使用BF16或FP16精度。
# 推理引擎后端 pytorch | tensorrt
TRT_BACKEND=pytorch
# ‼️模型路径
MODEL_PATH="/workspace/DeepSeek-R1/"
# 启动进程数量,对应到miprun的np
NUM_PROCESSES=16
# Tensor并行度(Tensor parallelism size)
TP_SIZE=16
# 流水线并行(Pipeline parallelism size)
PP_SIZE=1
# Expert并行度,对于moe架构模型才有效.(expert parallelism size)
EP_SIZE=8
# 最大批处理大小(Maximum number of requests that the engine can schedule.)
MAX_BATCH_SIZE=128
# 最大Token数(Maximum number of batched input tokens after padding is removed in each batch.)
MAX_NUM_TOKENS=8192
# KV缓存占GPU内存比例
KV_CACHE_FRACTION=0.95
# 额外配置文件名
ENABLE_EXTRA_CONFIG=true
EXTRA_CONFIG="extra-llm-api-config.yml" 

# 服务端口
SERVER_PORT=40000
# 是否后台启动,后台启动后ctrl+c容器不会退出
RUN_IN_BACKGROUND=true
# 运行的日志路径
LOG_FILE=/var/log/trt-llm/server.log